{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.testing as npt\n",
    "import PIL.Image as Image\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../utils\")\n",
    "\n",
    "from tflego import blocks\n",
    "from tflego import training\n",
    "from tflego.blocks import NP_DTYPE, TF_DTYPE, NP_ITYPE, TF_ITYPE\n",
    "import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"/tmp/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(output_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x5cd6750>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAEkRJREFUeJzt3X+sXHWZx/H3I0JqS2pjWVuyJVqpG0OiCHVlu4qWrYpC\nUuUflFWRNYCAEqNhRaKhLPxhrEEhmm5wkwWJqwnGdXFNfygEV1gWS0pAkF+BFlFarlQamlAKtTz7\nx8xNrpdye+beOTwzc9+vZBLmzNN7ntPv7YfvfOecM5GZSJJqvKq6AUmazQxhSSpkCEtSIUNYkgoZ\nwpJUyBCWpEKGsCQVMoQlqZAhLEmFXl3dQEQsBE4GHgP21nYjSX0xB3gjsCkz/zRVYWshHBGfBS4C\nFgP3ABdm5p0HKD0Z+I+2+pCkQh8HfjBVQSvLERHxUeBKYA1wHJ0Q3hQRRxyg/LE2epCkAfDYwQra\nWhP+AnBNZl6fmQ8C5wF7gE8foNYlCEmj6qD51vcQjohDgeXAzePbsnOrtpuAFf3enyQNszZmwkcA\nhwBjk7aP0VkfliR1eYqaJBVqI4R3AvuBRZO2LwKebGF/kjS0+h7CmbkP2AKsGt8WEdF9fnu/9ydJ\nw6yt84S/CVwXEVuAzXTOlpgLXNfS/iRpKLUSwpl5Q/ec4MvpLEPcDZycmU+1sT9JGlZR/UWfEXE8\nneULSRo1yzPzrqkKPDtCkgoZwpJUyBCWpEKGsCQVMoQlqZAhLEmFDGFJKmQIS1IhQ1iSChnCklTI\nEJakQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKGcKSVMgQlqRChrAkFTKEJamQISxJhQxhSSpk\nCEtSIUNYkgoZwpJUyBCWpEKGsCQVMoQlqZAhLEmFDGFJKmQIS1IhQ1iSChnCklTIEJakQoawJBUy\nhCWpkCEsSYUMYUkqZAhLUiFDWJIKGcKSVMgQlqRChrAkFep7CEfEmoh4cdLj/n7vR5JGwatb+rn3\nAauA6D7/c0v7kaSh1lYI/zkzn2rpZ0vSyGhrTfjNEfFERDwaEd+PiKNa2o8kDbU2QvgO4CzgZOA8\nYCnwq4iY18K+JGmo9X05IjM3TXh6X0RsBn4HnA5c2+/9SdIwa/0Utcx8BngYWNb2viRp2LQewhFx\nOJ0A3tH2viRp2LRxnvA3IuI9EfGGiPh74CfAPuCH/d6XJA27Nk5RWwL8AFgIPAXcBvxdZv6phX1J\n0lBr44O5M/r9MyVpVHnvCEkqZAhLUiFDWJIKGcKSVMgQlqRChrAkFTKEJamQISxJhQxhSSpkCEtS\nIUNYkgq19R1zmqZzzz23ce2FF17YuHZsbKxx7Z49exrXfve7321cu3Xr1sa199/vF3RrdnAmLEmF\nDGFJKmQIS1IhQ1iSChnCklTIEJakQoawJBUyhCWpkCEsSYUMYUkqFJlZ20DE8cCW0iYGyK5duxrX\nvva1r22xk/574YUXGtc+8cQTLXYi6O1S9q985SuNa2+55ZbptDOqlmfmXVMVOBOWpEKGsCQVMoQl\nqZAhLEmFDGFJKmQIS1IhQ1iSChnCklTIEJakQoawJBXy25YHTC/ftnz88cc3rr333nsb1771rW9t\nXLtixYrGtccdd1zj2qVLlzau3b17d+Pa+fPnN65t04svvti4tpdvvz788MMb1/byd3z22Wc3rvWy\n5d44E5akQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKGcKSVMgQlqRChrAkFfKy5QHzox/9qJXa\nQbBw4cLGtSeddFLj2ptuuqlx7fvf//7GtW3q5VLkLVuafxn51q1bG9fOmTOnce1DDz3UuFa96Xkm\nHBEnRsRPI+KJiHgxIlYfoObyiNgeEXsi4hcRsaw/7UrSaJnOcsQ84G7gAiAnvxgRFwOfA84F3gk8\nC2yKiMNm0KckjaSelyMycyOwESAi4gAlnweuyMyfdWvOBMaAjwA3TL9VSRo9ff1gLiKWAouBm8e3\nZeZu4NdA83seStIs0e+zIxbTWaIYm7R9rPuaJGkCT1GTpEL9DuEngQAWTdq+qPuaJGmCvoZwZm6j\nE7arxrdFxHzgBOD2fu5LkkZBz2dHRMQ8YBmdGS/AmyLiWODpzPw9cBXw1Yh4BHgMuAL4A3BjXzqW\npBEynSvm3gHcQucDuASu7G7/HvDpzFwbEXOBa4AFwK3AhzLzhT70K0kjJTJfcr3FK9tAxPFA8+sy\npVnmnHPOaVx7zTXXNK7dsWNH49pjjz22ce3OnTsb184CyzPzrqkKPDtCkgoZwpJUyBCWpEKGsCQV\nMoQlqZAhLEmFDGFJKmQIS1IhQ1iSChnCklTIb1uWChx55JGNa7/1rW81rj3wN44d2GWXXda41kuR\n2+NMWJIKGcKSVMgQlqRChrAkFTKEJamQISxJhQxhSSpkCEtSIUNYkgoZwpJUyMuWpQKXXnpp49q5\nc+c2rt27d2/j2nvuuadxrdrjTFiSChnCklTIEJakQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIK\nGcKSVMgQlqRC3jtC6pNTTz21ce0555zTSg8f+9jHGtdu3ry5lR7UG2fCklTIEJakQoawJBUyhCWp\nkCEsSYUMYUkqZAhLUiFDWJIKGcKSVMgQlqRCPV+2HBEnAv8MLAeOBD6SmT+d8Pq1wKcm/bGNmXnK\nTBqVBt1pp53WuPZVr2o+/3nggQca165fv75xrQbDdGbC84C7gQuAfJmaDcAiYHH3cca0upOkEdfz\nTDgzNwIbASIiXqbs+cx8aiaNSdJs0Naa8MqIGIuIByNiXUS8rqX9SNJQa+NWlhuAHwPbgKOBrwHr\nI2JFZr7c8oUkzUp9D+HMvGHC099GxL3Ao8BK4JZ+70+Shlnrp6hl5jZgJ7Cs7X1J0rBpPYQjYgmw\nENjR9r4kadhM5zzheXRmteNnRrwpIo4Fnu4+1tBZE36yW/d14GFgUz8alqRRMp014XfQWdvN7uPK\n7vbv0Tl3+G3AmcACYDud8L00M/fNuFtJGjHTOU/4f5h6GeOD029HkmYXv21ZmsLcuXMb137gAx9o\nXLt///7GtRdddFHj2n37fMM5bLyBjyQVMoQlqZAhLEmFDGFJKmQIS1IhQ1iSChnCklTIEJakQoaw\nJBUyhCWpkJctS1NYu3Zt49olS5Y0rv3Nb37TuHbDhg2NazV8nAlLUiFDWJIKGcKSVMgQlqRChrAk\nFTKEJamQISxJhQxhSSpkCEtSIUNYkgp52bJmlU9+8pM91Z9//vmNa59//vnGtV/+8pd76kOjy5mw\nJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKGcKSVMgQlqRChrAkFTKEJamQly1r6L3+9a9vXHv11Vf3\n9LMjonHtnXfe2bh248aNPfWh0eVMWJIKGcKSVMgQlqRChrAkFTKEJamQISxJhQxhSSpkCEtSIUNY\nkgoZwpJUqKfLliPiEuA04C3Ac8DtwMWZ+fCkusuBs4EFwP8C52fmI33pWLPCIYcc0ri2l8uFFyxY\n0FMfu3btalz7mc98pqefLUHvM+ETgW8DJwDvAw4Ffh4RrxkviIiLgc8B5wLvBJ4FNkXEYX3pWJJG\nSE8z4cw8ZeLziDgL+COwHLitu/nzwBWZ+bNuzZnAGPAR4IYZ9itJI2Wma8ILgASeBoiIpcBi4Obx\ngszcDfwaWDHDfUnSyJl2CEfnHn9XAbdl5v3dzYvphPLYpPKx7muSpAlmcj/hdcAxwLv61IskzTrT\nmglHxHeAU4CVmbljwktPAgEsmvRHFnVfkyRN0HMIdwP4w8BJmfn4xNcycxudsF01oX4+nbMpbp9Z\nq5I0eno9T3gdcAawGng2IsZnvM9k5t7uf18FfDUiHgEeA64A/gDc2JeOJWmE9LomfB6dD95+OWn7\nPwHXA2Tm2oiYC1xD5+yJW4EPZeYLM2tVkkZPr+cJN1q+yMzLgMum0Y8kzSp+27IG0jHHHNO49qij\njmqtjy9+8YuNax944IHW+tDo8gY+klTIEJakQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKGcKS\nVMgQlqRCXrasV8zRRx/duPbWW29tpYe1a9f2VH/99de30oc0zpmwJBUyhCWpkCEsSYUMYUkqZAhL\nUiFDWJIKGcKSVMgQlqRChrAkFTKEJamQly3rFXPJJZc0rp0/f34rPWzatKmn+sxspQ9pnDNhSSpk\nCEtSIUNYkgoZwpJUyBCWpEKGsCQVMoQlqZAhLEmFDGFJKmQIS1IhQ1iSCnnvCM3I6tWrG9d+4hOf\naLETaTg5E5akQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKGcKSVMgQlqRChrAkFerpsuWIuAQ4\nDXgL8BxwO3BxZj48oeZa4FOT/ujGzDxlhr1qAK1cubJx7WGHHdZKD7t27WqlVnol9DoTPhH4NnAC\n8D7gUODnEfGaSXUbgEXA4u7jjBn2KUkjqaeZ8OTZbEScBfwRWA7cNuGl5zPzqRl3J0kjbqZrwguA\nBJ6etH1lRIxFxIMRsS4iXjfD/UjSSJr2rSwjIoCrgNsy8/4JL20AfgxsA44Gvgasj4gVmZkzaVaS\nRs1M7ie8DjgGeNfEjZl5w4Snv42Ie4FHgZXALTPYnySNnGktR0TEd4BTgJWZuWOq2szcBuwElk1n\nX5I0ynqeCXcD+MPAezPz8Qb1S4CFwJRhLUmzUU8z4YhYB3wc+Efg2YhY1H3M6b4+LyLWRsQJEfGG\niFgF/BfwMLCp381L0rDrdTniPGA+8Etg+4TH6d3X9wNvA24EHgL+DbgTeE9m7utDv5I0Uno9T3jK\n0M7MvcAHZ9SRJM0iftuyBtL27dsb17797W9vXLtz587ptCO1xhv4SFIhQ1iSChnCklTIEJakQoaw\nJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKRfWXXUTE8cCW0iYkqR3LM/OuqQqcCUtSIUNYkgoZwpJU\nyBCWpEKGsCQVMoQlqZAhLEmFDGFJKmQIS1KhQQjhOdUNSFJLDppvgxDCb6xuQJJa8saDFQzCvSMW\nAicDjwF7S5uRpP6YQyeAN2Xmn6YqLA9hSZrNBmE5QpJmLUNYkgoZwpJUyBCWpEIDGcIR8dmI2BYR\nz0XEHRHxt9U99UNErImIFyc97q/uazoi4sSI+GlEPNE9jtUHqLk8IrZHxJ6I+EVELKvodToOdnwR\nce0BxnJ9Vb9NRcQlEbE5InZHxFhE/CQi/uYAdUM5dk2Ob9DGbuBCOCI+ClwJrAGOA+4BNkXEEaWN\n9c99wCJgcffx7tp2pm0ecDdwAfCSU2wi4mLgc8C5wDuBZ+mM42GvZJMzMOXxdW3gL8fyjFemtRk5\nEfg2cALwPuBQ4OcR8ZrxgiEfu4MeX9fgjF1mDtQDuAO4esLzAP4AfKm6tz4c2xrgruo+WjiuF4HV\nk7ZtB74w4fl84Dng9Op++3R81wL/Wd1bH47tiO7xvXtEx+5AxzdQYzdQM+GIOBRYDtw8vi07f2s3\nASuq+uqzN3ff4j4aEd+PiKOqG+q3iFhKZ3YxcRx3A79mdMYRYGX3Le+DEbEuIl5X3dA0LKAz038a\nRnLs/uL4JhiYsRuoEKbzf61DgLFJ28fo/GIMuzuAs+hcIXgesBT4VUTMq2yqBYvp/OKP6jhC5+3s\nmcA/AF8C3gusj4go7aoH3V6vAm7LzPHPJkZm7F7m+GDAxu7VFTudrTJz04Sn90XEZuB3wOl03iJp\nSGTmDROe/jYi7gUeBVYCt5Q01bt1wDHAu6obackBj2/Qxm7QZsI7gf10FswnWgQ8+cq3067MfAZ4\nGBiKT5578CSdtfxZMY4AmbmNzu/vUIxlRHwHOAVYmZk7Jrw0EmM3xfG9RPXYDVQIZ+Y+YAuwanxb\n9y3CKuD2qr7aEhGH0xn4KX9Jhk33l/pJ/nIc59P5xHrkxhEgIpYACxmCsewG1IeBkzLz8YmvjcLY\nTXV8L1NfOnaDuBzxTeC6iNgCbAa+AMwFrqtsqh8i4hvAf9NZgvhr4F+AfcAPK/uaju469jI6syaA\nN0XEscDTmfl7OmtxX42IR+jcIe8KOme53FjQbs+mOr7uYw3wYzqBtQz4Op13NZte+tMGR0Sso3M6\n1mrg2YgYn/E+k5njdzEc2rE72PF1x3Wwxq769IyXOa3kAjqD/xzwf8A7qnvq03H9kM4v83PA48AP\ngKXVfU3zWN5L59Sf/ZMe/z6h5jI6pzvtofMLvqy6734cH53bFG6k8494L7AV+Ffgr6r7bnBcBzqm\n/cCZk+qGcuwOdnyDOHbeylKSCg3UmrAkzTaGsCQVMoQlqZAhLEmFDGFJKmQIS1IhQ1iSChnCklTI\nEJakQoawJBUyhCWpkCEsSYX+H8U18LW8XnM6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x372e850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(mnist.test.images[0, :], (28, 28)), cmap=\"Greys_r\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'RNN/BasicRNNCell/Linear/Matrix:0', u'RNN/BasicRNNCell/Linear/Bias:0']\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# Test data\n",
    "n_input = 3\n",
    "n_data = 4\n",
    "n_maxlength = 5\n",
    "test_data = np.zeros((n_data, n_maxlength, n_input), dtype=NP_DTYPE)\n",
    "lengths = []\n",
    "for i_data in xrange(n_data):\n",
    "    length = np.random.randint(1, n_maxlength + 1)\n",
    "    lengths.append(length)\n",
    "    test_data[i_data, :length, :] = np.random.randn(length, n_input)\n",
    "lengths = np.array(lengths, dtype=NP_ITYPE)\n",
    "\n",
    "# Model parameters\n",
    "n_hidden = 6\n",
    "rnn_type = \"rnn\"\n",
    "\n",
    "# TensorFlow model\n",
    "x = tf.placeholder(TF_DTYPE, [None, n_maxlength, n_input])\n",
    "x_lengths = tf.placeholder(TF_DTYPE, [None])\n",
    "rnn_outputs, rnn_states = blocks.build_rnn(x, x_lengths, n_hidden, rnn_type=rnn_type)\n",
    "\n",
    "print [v.name for v in tf.all_variables()]\n",
    "with tf.variable_scope(\"RNN/BasicRNNCell/Linear\", reuse=True):\n",
    "    W = tf.get_variable(\"Matrix\")\n",
    "    b = tf.get_variable(\"Bias\")\n",
    "\n",
    "# TensorFlow graph\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "\n",
    "    # Output\n",
    "    tf_output = rnn_outputs.eval({x: test_data, x_lengths: lengths})\n",
    "    tf_states = rnn_states.eval({x: test_data, x_lengths: lengths})\n",
    "\n",
    "    # Weights\n",
    "    W = W.eval()\n",
    "    b = b.eval()\n",
    "\n",
    "# Numpy model\n",
    "# np_output = np_rnn(test_data, lengths, W, b, n_maxlength)\n",
    "\n",
    "\n",
    "# npt.assert_almost_equal(tf_output, np_output, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asd', 'c', 'ddd']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "b = [\"asd\", \"ddd\", \"c\"]\n",
    "np.random.shuffle(b)\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!! Tensor(\"rnn_encoder/transpose:0\", shape=(?, 5, 6), dtype=float32)\n",
      "rnn_encoder/transpose:0\n",
      "Tensor(\"rnn_decoder/zeros:0\", shape=(?, 3), dtype=float32)\n",
      "(4, 5, 6)\n",
      "(4, 6)\n",
      "(4, 5, 3)\n",
      "(4, 5, 3)\n",
      "[u'rnn_encoder/BasicRNNCell/Linear/Matrix:0', u'rnn_encoder/BasicRNNCell/Linear/Bias:0', u'rnn_decoder/BasicRNNCell/Linear/Matrix:0', u'rnn_decoder/BasicRNNCell/Linear/Bias:0', u'rnn_decoder/linear_output/W:0', u'rnn_decoder/linear_output/b:0']\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(1)\n",
    "# tf.set_random_seed(1)\n",
    "\n",
    "# Test data\n",
    "n_input = 3\n",
    "n_data = 4\n",
    "n_maxlength = 5\n",
    "test_data = np.zeros((n_data, n_maxlength, n_input), dtype=NP_DTYPE)\n",
    "lengths = []\n",
    "for i_data in xrange(n_data):\n",
    "    length = np.random.randint(1, n_maxlength + 1)\n",
    "    lengths.append(length)\n",
    "    test_data[i_data, :length, :] = np.random.randn(length, n_input)\n",
    "lengths = np.array(lengths, dtype=NP_ITYPE)\n",
    "\n",
    "# Model parameters\n",
    "n_hidden = 6\n",
    "n_output = n_input\n",
    "rnn_type = \"rnn\"\n",
    "\n",
    "# TensorFlow model\n",
    "x = tf.placeholder(TF_DTYPE, [None, n_maxlength, n_input])\n",
    "x_lengths = tf.placeholder(TF_DTYPE, [None])\n",
    "rnn_outputs, rnn_states = blocks.build_rnn(x, x_lengths, n_hidden, rnn_type=rnn_type, scope=\"rnn_encoder\")\n",
    "print \"!\"*5, rnn_outputs\n",
    "print rnn_outputs.name\n",
    "\n",
    "def unpack_sequence(tensor):\n",
    "    \"\"\"Split the single tensor of a sequence into a list of frames.\"\"\"\n",
    "    return tf.unpack(tf.transpose(tensor, perm=[1, 0, 2]))\n",
    "\n",
    "def pack_sequence(sequence):\n",
    "    \"\"\"Combine a list of the frames into a single tensor of the sequence.\"\"\"\n",
    "    return tf.transpose(tf.pack(sequence), perm=[1, 0, 2])\n",
    "\n",
    "\n",
    "def build_encdec_lazydynamic():\n",
    "    pass\n",
    "\n",
    "\n",
    "def build_encdec_outback():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_rnn_decoder_outback(initial_state, n_hidden, n_output, maxlength,\n",
    "        rnn_type=\"lstm\", initial_prev_output=None, dtype=None, **kwargs):\n",
    "    \"\"\"In this decoder the output is fed back as input.\"\"\"\n",
    "\n",
    "    with tf.variable_scope(\"rnn_decoder\") as scope:\n",
    "    \n",
    "        # RNN decoder cell\n",
    "        cell = blocks.build_rnn_cell(n_hidden, rnn_type, **kwargs)\n",
    "\n",
    "        # Initial state and input\n",
    "        state = initial_state\n",
    "        if rnn_type == \"lstm\":\n",
    "            batch_size = tf.shape(initial_state[0])[0]  # cell and hidden states together in tuple\n",
    "        elif rnn_type == \"gru\" or rnn_type == \"rnn\":\n",
    "            batch_size = tf.shape(initial_state)[0]\n",
    "        if initial_prev_output is not None:\n",
    "            prev_output = initial_prev_output\n",
    "        else:\n",
    "            if not dtype:\n",
    "                raise ValueError(\"If no initial_prev_output is provided, dtype must be.\")\n",
    "            prev_output = tf.zeros([batch_size, n_output], dtype)\n",
    "            prev_output.set_shape([None, n_output])\n",
    "            print prev_output\n",
    "        \n",
    "        # Decode over timesteps\n",
    "        outputs = []\n",
    "        for i_time in xrange(maxlength):\n",
    "            if i_time > 0:\n",
    "                scope.reuse_variables()\n",
    "            output, state = cell(prev_output, state)\n",
    "            with tf.variable_scope(\"linear_output\"):\n",
    "                output = blocks.build_linear(output, n_output)\n",
    "            outputs.append(output)\n",
    "            prev_output = output\n",
    "\n",
    "        return pack_sequence(outputs)\n",
    "\n",
    "# print \"4\", rnn_states\n",
    "#     rnn_states = rnn_states\n",
    "rnn_decoder = build_rnn_decoder_outback(rnn_states, n_hidden, n_output, n_maxlength, rnn_type, dtype=TF_DTYPE)\n",
    "\n",
    "\n",
    "#     for i_time in xrange(max_length):\n",
    "        \n",
    "        \n",
    "#         if i > 0:\n",
    "#             variable_scope.get_variable_scope().reuse_variables()\n",
    "            \n",
    "\n",
    "\n",
    "with tf.variable_scope(\"rnn_encoder/BasicRNNCell/Linear\", reuse=True):\n",
    "    W = tf.get_variable(\"Matrix\")\n",
    "    b = tf.get_variable(\"Bias\")\n",
    "with tf.variable_scope(\"rnn_decoder/BasicRNNCell/Linear\", reuse=True):\n",
    "    W_rnn_decoder = tf.get_variable(\"Matrix\")\n",
    "    b_rnn_decoder = tf.get_variable(\"Bias\")\n",
    "with tf.variable_scope(\"rnn_decoder/linear_output\", reuse=True):\n",
    "    W_rnn_output = tf.get_variable(\"W\")\n",
    "    b_rnn_output = tf.get_variable(\"b\")\n",
    "\n",
    "    \n",
    "# TensorFlow graph\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "\n",
    "    # Output\n",
    "    tf_output = rnn_outputs.eval({x: test_data, x_lengths: lengths})\n",
    "#     tf_states = rnn_states.eval({x: test_data, x_lengths: lengths})\n",
    "    tf_decoder = rnn_decoder.eval({x: test_data, x_lengths: lengths})\n",
    "\n",
    "    # Weights\n",
    "    W = W.eval()\n",
    "    b = b.eval()\n",
    "    W_rnn_decoder = W_rnn_decoder.eval()\n",
    "    b_rnn_decoder = b_rnn_decoder.eval()\n",
    "    W_rnn_output = W_rnn_output.eval()\n",
    "    b_rnn_output = b_rnn_output.eval()\n",
    "\n",
    "# # Numpy model\n",
    "np_output = blocks.np_rnn(test_data, lengths, W, b, n_maxlength)\n",
    "\n",
    "def np_rnn_decoder_outback(initial_states, W_hidden, b_hidden, W_output,\n",
    "        b_output, max_length):\n",
    "    \"\"\"\n",
    "    In this decoder the output is fed back as input.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    initial_hiddens : matrix [batch_size, n_hidden]\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for i_data in xrange(initial_states.shape[0]):\n",
    "        output = []\n",
    "        prev_output = np.zeros(W_output.shape[1])\n",
    "        prev_state = initial_states[i_data]\n",
    "        for i_time in xrange(max_length):\n",
    "            cur_state = np.tanh(np.dot(np.hstack((prev_output, prev_state)), W_hidden) + b_hidden)\n",
    "            cur_output = np.dot(cur_state, W_output) + b_output\n",
    "            prev_state = cur_state\n",
    "            prev_output = cur_output\n",
    "            output.append(cur_output)\n",
    "        outputs.append(output)\n",
    "    return np.array(outputs)\n",
    "\n",
    "initial_state = []\n",
    "for i_data, l in enumerate(lengths):\n",
    "    initial_state.append(np_output[i_data, l - 1, :])\n",
    "initial_state = np.array(initial_state)\n",
    "        \n",
    "np_decoder = np_rnn_decoder_outback(\n",
    "    initial_state, W_rnn_decoder, b_rnn_decoder, W_rnn_output, b_rnn_output, n_maxlength\n",
    "    )\n",
    "\n",
    "print tf_output.shape\n",
    "print tf_states.shape\n",
    "print tf_decoder.shape\n",
    "print test_data.shape\n",
    "\n",
    "print [v.name for v in tf.all_variables()]\n",
    "\n",
    "npt.assert_almost_equal(tf_output, np_output, decimal=5)\n",
    "npt.assert_almost_equal(tf_decoder, np_decoder, decimal=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 5, 3]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 3)\n",
      "(4, 5, 6)\n",
      "(4, 6)\n",
      "(4, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(1)\n",
    "# tf.set_random_seed(1)\n",
    "\n",
    "# Test data\n",
    "n_input = 3\n",
    "n_data = 4\n",
    "n_maxlength = 5\n",
    "test_data = np.zeros((n_data, n_maxlength, n_input), dtype=NP_DTYPE)\n",
    "lengths = []\n",
    "for i_data in xrange(n_data):\n",
    "    length = np.random.randint(1, n_maxlength + 1)\n",
    "    lengths.append(length)\n",
    "    test_data[i_data, :length, :] = np.random.randn(length, n_input)\n",
    "lengths = np.array(lengths, dtype=NP_ITYPE)\n",
    "\n",
    "# Model parameters\n",
    "n_hidden = 6\n",
    "n_output = n_input\n",
    "rnn_type = \"rnn\"\n",
    "\n",
    "# TensorFlow model\n",
    "x = tf.placeholder(TF_DTYPE, [None, n_maxlength, n_input])\n",
    "x_lengths = tf.placeholder(TF_DTYPE, [None])\n",
    "rnn_outputs, rnn_states = blocks.build_rnn(x, x_lengths, n_hidden, rnn_type=rnn_type, scope=\"rnn_encoder\")\n",
    "rnn_repeat_states = tf.reshape(tf.tile(rnn_states, [1, n_maxlength]), [-1, n_maxlength, n_hidden])\n",
    "rnn_decoder_outputs, rnn_decoder_states = blocks.build_rnn(rnn_repeat_states, x_lengths, n_hidden, rnn_type=rnn_type, scope=\"rnn_decoder\")\n",
    "with tf.variable_scope(\"rnn_decoder\"):\n",
    "    with tf.variable_scope(\"linear_output\"):\n",
    "        rnn_decoder_outputs = tf.reshape(rnn_decoder_outputs, [-1, n_hidden])\n",
    "        rnn_decoder_outputs = blocks.build_linear(rnn_decoder_outputs, n_output)\n",
    "        rnn_decoder_outputs = tf.reshape(rnn_decoder_outputs, [-1, n_maxlength, n_output])\n",
    "\n",
    "with tf.variable_scope(\"rnn_encoder/BasicRNNCell/Linear\", reuse=True):\n",
    "    W = tf.get_variable(\"Matrix\")\n",
    "    b = tf.get_variable(\"Bias\")\n",
    "with tf.variable_scope(\"rnn_decoder/BasicRNNCell/Linear\", reuse=True):\n",
    "    W_rnn_decoder = tf.get_variable(\"Matrix\")\n",
    "    b_rnn_decoder = tf.get_variable(\"Bias\")\n",
    "with tf.variable_scope(\"rnn_decoder/linear_output\", reuse=True):\n",
    "    W_rnn_output = tf.get_variable(\"W\")\n",
    "    b_rnn_output = tf.get_variable(\"b\")\n",
    "\n",
    "# TensorFlow graph\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "\n",
    "    # Output\n",
    "    tf_encoder = rnn_outputs.eval({x: test_data, x_lengths: lengths})\n",
    "    tf_states = rnn_states.eval({x: test_data, x_lengths: lengths})\n",
    "    rnn_repeat_states = rnn_repeat_states.eval({x: test_data, x_lengths: lengths})\n",
    "    rnn_decoder_outputs = rnn_decoder_outputs.eval({x: test_data, x_lengths: lengths})\n",
    "\n",
    "    # Weights\n",
    "    W_rnn_encoder = W.eval()\n",
    "    b_rnn_encoder = b.eval()\n",
    "    W_rnn_decoder = W_rnn_decoder.eval()\n",
    "    b_rnn_decoder = b_rnn_decoder.eval()\n",
    "    W_rnn_output = W_rnn_output.eval()\n",
    "    b_rnn_output = b_rnn_output.eval()    \n",
    "    \n",
    "print test_data.shape\n",
    "print tf_encoder.shape\n",
    "print tf_states.shape\n",
    "# print tf_states\n",
    "# print rnn_repeat_states.shape\n",
    "# print rnn_repeat_states\n",
    "# print tf_states\n",
    "print rnn_decoder_outputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_encoder = blocks.np_rnn(test_data, lengths, W_rnn_encoder, b_rnn_encoder, n_maxlength)\n",
    "\n",
    "rnn_states = []\n",
    "for i_data, l in enumerate(lengths):\n",
    "    rnn_states.append(np_encoder[i_data, l - 1, :])\n",
    "rnn_states = np.array(rnn_states)\n",
    "\n",
    "np_states_repeated = np.reshape(np.repeat(rnn_states, n_maxlength, axis=0), [-1, n_maxlength, n_hidden])\n",
    "np_decoder = blocks.np_rnn(np_states_repeated, lengths, W_rnn_decoder, b_rnn_decoder, n_maxlength)\n",
    "\n",
    "x = np_decoder\n",
    "x_lengths = lengths\n",
    "maxlength = n_maxlength\n",
    "outputs = np.zeros((x.shape[0], maxlength, n_output))\n",
    "for i_data in xrange(x.shape[0]):\n",
    "    cur_x_sequence = x[i_data, :, :]\n",
    "    for i_step, cur_x in enumerate(cur_x_sequence):\n",
    "#         print cur_x\n",
    "        outputs[i_data, i_step, :] = blocks.np_linear(cur_x, W_rnn_output, b_rnn_output)\n",
    "#     break\n",
    "\n",
    "# print np_encoder\n",
    "# print rnn_states\n",
    "# print np_decoder\n",
    "\n",
    "\n",
    "# print rnn_decoder_outputs\n",
    "# print outputs\n",
    "\n",
    "npt.assert_almost_equal(outputs, rnn_decoder_outputs, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 6)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_rnn_encoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
